{
  "name": "Pymcz",
  "tagline": "montecarlo sampling method to calculate metalicity from flux data",
  "body": "[![DOI](https://zenodo.org/badge/doi/10.5281/zenodo.17880.svg)](http://dx.doi.org/10.5281/zenodo.17880) [![Code Health](https://landscape.io/github/fedhere/pyMCZ/master/landscape.svg?style=flat)](https://landscape.io/github/fedhere/pyMCZ/master)\r\n\r\nMC Metallicity\r\n====================\r\n\r\nThis code allows the user to calculate metallicity according to a number of <i> strong line metallicity diagnostics </i> from spectroscopy line measurements, and obtain uncertainties from the line flux errors in a Monte Carlo framework. If you use this code, <b> please cite our [paper] (http://www.sciencedirect.com/science/article/pii/S2213133716300178) which is published in [Astronomy and Computing](http://www.journals.elsevier.com/astronomy-and-computing/) and also available on the [arxiv](http://arxiv.org/abs/1505.06213).</b>\r\n\r\n    @ARTICLE{2016A&C....16...54B,\r\n       author = {{Bianco}, F.~B. and {Modjaz}, M. and {Oh}, S.~M. and {Fierroz}, D. and \r\n\t    {Liu}, Y.~Q. and {Kewley}, L. and {Graur}, O.},\r\n        title = \"{Monte Carlo method for calculating oxygen abundances and their uncertainties from strong-line flux measurements}\",\r\n      journal = {Astronomy and Computing},\r\n    archivePrefix = \"arXiv\",\r\n      eprint = {1505.06213},\r\n    primaryClass = \"astro-ph.IM\",\r\n    keywords = {Galaxy, Abundances-ISM, HII regions-supernovae, General},\r\n         year = 2016,\r\n        month = jul,\r\n      volume = 16,\r\n        pages = {54-66},\r\n          doi = {10.1016/j.ascom.2016.03.002},\r\n      adsurl = {http://adsabs.harvard.edu/abs/2016A%26C....16...54B},\r\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\r\n    }\r\n\r\n\r\n\r\nThis code is released under MIT licence: see LICENSE.txt\r\n\r\n<b>Most recent stable release: v1.3</b>\r\n\r\n====================\r\nUsage:\r\n====================\r\nThis code requires ascii input files, their format is described below and examples are provided in the \\<input\\> directory in this package.  We provide an example dataset names 'exampledata', i.e. we provide input files 'exampledata_meas.txt' and 'exampledata_err.txt' are the input files. \r\n\r\nFrom the commandline simply use as:\r\n```\r\npython mcz.py <filename> nsample --path PATH \r\n```\r\n<b>\\<filename\\></b>: \\<filename\\> is the root name for the input as well as for all the output files: it could be for example the name of the supernova at the location of which HII regions have been measured (\\<filename\\> is 'exampledata' in our examples)\r\n\r\n<b>nsample</b>: the number of MC samples desired (for exampledata 2000 is an appropriate sample size. \r\n                       nsample must be >100 or it can be 0 to produce a single value, and no confidence region \r\n\r\nadditional command line arguments\r\n\r\n <b> --path PATH  </b>         the directory in which subdirectory \"input\" is located. If not provided, will default\r\n                        environmental variable MCMetdata that should be set to point to that directory. \r\n                        In our example the input directory is in pyMCZ (level 1).\r\n                        _err.txt _meas.txt must live in \\<path\\>/input\r\n                        \r\n <b> --md MD      </b>         metallicity scales to calculate. default is 'all',\r\n                        options are: D02, Z94, M91, M08, P05,P10, PP04, M13, D13, KD02,\r\n                        KD02comb, DP00 (deprecated), P01 (deprecated), C01 (deprecated)\r\n                        \r\n<b>  --unpickle    </b>        if it exists, a pickle file generated in a previous run for this \\<filename\\> and this \r\n                        number of samples is read in instead of recalculating the metalicity\r\n\r\n<b>  --binmode  BM  </b>         how to choose the number of bins for plotting the histogram:\r\n                            'd' is based on Doane's formula (wikipedia's version),  \r\n                            's' is the sqrt of number of data,        \r\n                            't' is on 2*n**1/3 , \r\n                            'kb' uses Knuth's block rule (default), \r\n                            'bb' uses bayesian blocks (must have astroML installed or it defaults to 'kb')\r\n                            'kd' is the kernel density, which requires sklearn installed and additioinally plots the                             histogram with 'kb' mode\r\n\r\n<b>  --clobber   </b>          If set to true, will overwrite existing output files without asking. Default False.\r\n\r\n<b>  --verbose   </b>          verbose mode. Default False.\r\n\r\n<b>  --nodust    </b>          don't do dust corrections (default is to do it)\r\n\r\n<b>  --noplot    </b>          don't plot individual distributions (default is to\r\n                        plot all distributions)\r\n\r\n<b>  --asciiout   </b>         write distribution medians and 68% inclusion regions in an ascii output (default is not\r\n                        to)\r\n                        \r\n<b>  --asciidistrib  </b>       write the entire distribution for every scale in an ascii file output (default is not to)\r\n                        \r\n                        \r\n<b>  --multiproc (--multi)  </b>         multiprocess, with number of threads nps=max(available cores-1, MAXPROCESSES)\r\n\r\n<b>  --log LOGFILE  </b>       outputting messages to a log file instead of standard output. disabled when multiprocessing\r\n\r\n\r\n====================\r\nInput file format\r\n====================\r\nFlux data for each object should be stored in the directory \\<input\\> that exists in the directory provided by the --path arg or by the environmental variable MCMetdata. Their ascii file names are expected to end by \"\\_meas.txt\" for the file containing the measurements, and \"\\_err.txt\" for the error file.\r\n\r\nwith common filename \\<filename\\>:\r\n\r\n\\<filename\\>_err.txt\r\n\r\n\\<filename\\>_meas.txt \r\n\r\nThe format for each of the txt files should be as follows, e.g.,\r\n\r\n\r\n;# galnum,[OII]3727,Hb,[OIII]4959,[OIII]5007,[OI]6300,Ha,[NII]6584,[SII]6717,[SII]6731,[SIII]9069,[SIII]9532\r\n       1     0.0     0.0     0.0     0.0     0.0   5.117   0.998     0.0     0.0     0.0     0.0\r\n       2     0.0     0.0     0.0     0.0     0.0   5.031   1.012     0.0     0.0     0.0     0.0\r\n       \r\n       \r\ngalnum is a sequential index\r\n\r\n\r\nThe first row is optional - it can contain more keys than columns, as long as the columns are listed in the same order as specified above, up to whichever line is of interest. Missing data should be filled in with 'NaN's.\r\n\r\nThe data should be in the above order, separated by any number of white spaces.\r\n\r\n\r\n====================\r\nOutput\r\n====================\r\nAll the results will be saved in the directory \"output/\\<filename\\>\" which will be creates in the directory provided by the --path arg.\r\n\r\nRead our [paper](http://www.sciencedirect.com/science/article/pii/S2213133716300178), or the README.md file in the output directory in this package https://github.com/nyusngroup/pyMCZ/blob/master/output/README.md for more details on the output products.\r\n\r\n\r\n====================\r\nTests implemented\r\n====================\r\n\r\nA few tests are implemented to make sure your inputs are valid, and your outputs are robust. \r\nIn order to assess if the number of samples requested is sufficiently large, we provide the module testcompleteness.py. \r\n\r\nUse as, for example: \r\n\r\nimport testcompleteness as tc\r\n\r\ntc.fitdistrib(\\<path to pickle file\\>)\r\n\r\n\r\nThis reads in the pickle file generated by the code, and compares the cumulative distributions for 4 parameters: E(B-V), D02, Z94 and KD02comb_updated (the user can choose to use whichever scale of course!) (choosing subsets with minimal invalid outpus for each subset).  \r\n\r\nThe cumulative distribution for 1/10, 1/4, 1/2, 3/4 and the full sample generated by the code are compared with a KS tests and plotted. \r\n\r\nIf the number of samples is sufficient, you should expect the probability of the 3/4 sample and full sample to come from the same parent distribution to be close to 1, and generally the KD p-value to increase with the sample fraction (but not always it turns out...). More importantly though this can be used visually: the cumulative distribution should be nearly identical (and smooth). If all distributions overlap, then you are sure that you are well above the critical sample size that achieves smoothness (by a factor 10).\r\n\r\nThe figures below show an undersampled realization and a well- (possibly) over-sampled realization.\r\n\r\n\r\n\r\n\r\n![alt tag](https://github.com/nyusngroup/pyMCZ/blob/master/figures/exampledata_n200_testcomplete.png)\r\n\r\n\r\n![alt tag](https://github.com/nyusngroup/pyMCZ/blob/master/figures/exampledata_n2000_testcomplete.png)\r\n\r\n\r\n![alt tag](https://github.com/nyusngroup/pyMCZ/blob/master/figures/exampledata_n20000_testcomplete.png)\r\n\r\n\r\n \r\n====================\r\nKnown Issues and TODO\r\n====================\r\n\r\n\r\nPlot formatting is designed for a platform using latex and with Times New Roman serif font available to matplotlib. The module pylabsetup loaded early on assures that the matplotlib rcparameters are set up appropriately, including font choice, and in case of missing fonts an error message is streamed (but not paused upon). If your plots don't look good, change the necessary parameters in pylabsetup.py. This is an unfortunately common occurrence when not running on a Mac.\r\n\r\n\r\nNote that while a PDF version of our paper is included in the repository, the PDF does not render properly in github. To see the paper please go to the arxiv link (http://arxiv.org/abs/1505.06213) or compile it with pdflatex in the repo \"paper\" directory on your local machine.\r\n\r\nThe input file is a but awkward, for historical reasons: we decided to make minimal modification tot he input files required by the original IDL code. An alternative, more pythonic input, may be made available in the future, when we have time.\r\n\r\nIt would be great to create sphyinx documentation.\r\n\r\n====================\r\nPackages required\r\n====================\r\nrequired packages:\r\n\r\nnumpy,pylab,matplotlib,scipy\r\n\r\ndesirable packages:\r\n\r\npickle,multiprocessing,itertools,csv,cProfile,pyqz\r\n\r\n\r\n===================\r\nSome figures from the paper as examples of code products\r\n===================\r\n\r\n\r\n![alt tag](https://github.com/nyusngroup/pyMCZ/blob/master/figures/pyMCZ_KD02distrib.png)\r\n\r\n\r\n![alt tag](https://github.com/nyusngroup/pyMCZ/blob/master/figures/pyMCZ_KD02distrib_KDE.png)\r\n\r\n\r\n![alt tag](https://github.com/nyusngroup/pyMCZ/blob/master/figures/pyMCZ_boxplot.png)\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}